# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

steps:

- script: |
    docker login --username $(DOCKER_HUB_USERNAME) --password $(DOCKER_HUB_PASSWORD)
  displayName: 'login to docker hub to allow push (https://hub.docker.com/u/triplai)'

- script: |
    export ARC_VERSION=2.0.0 && \
    export ARC_JUPYTER_VERSION=1.1.0 && \
    export SPARK_VERSION=2.4.3 && \
    export HADOOP_VERSION=2.9.2

- script: |
    export VERSION=$(cat arc/version) && \
    export SCALA_VERSION=2.11 && \
    docker build . \
    -f arc/Dockerfile_${SCALA_VERSION} \
    --build-arg ARC_VERSION \
    --build-arg SPARK_VERSION \
    --build-arg HADOOP_VERSION \
    -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION}
  displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.11_hadoop_${HADOOP_VERSION}_${VERSION}'

- script: |
    export VERSION=$(cat arc/version) && \
    export SCALA_VERSION=2.12 && \
    docker build . \
    -f arc/Dockerfile_${SCALA_VERSION} \
    --build-arg ARC_VERSION \
    --build-arg SPARK_VERSION \
    --build-arg HADOOP_VERSION \
    -t triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION}
  displayName: 'build triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.12_hadoop_${HADOOP_VERSION}_${VERSION}'

- script: |
    export VERSION=$(cat arc-jupyter/version) && \
    export SCALA_VERSION=2.11 && \
    docker build . \
    -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
    --build-arg ARC_JUPYTER_VERSION \
    --build-arg SPARK_VERSION \
    --build-arg HADOOP_VERSION \
    -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_${VERSION}
  displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.11_${VERSION}'

- script: |
    export VERSION=$(cat arc-jupyter/version) && \
    export SCALA_VERSION=2.12 && \
    docker build . \
    -f arc-jupyter/Dockerfile_${SCALA_VERSION} \
    --build-arg ARC_JUPYTER_VERSION \
    --build-arg SPARK_VERSION \
    --build-arg HADOOP_VERSION \
    -t triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_${VERSION}
  displayName: 'build triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.12_${VERSION}'

- script: |
    export VERSION=$(cat arc/version) && \
    export SCALA_VERSION=2.11 && \
    docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION}
  displayName: 'push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.11_hadoop_${HADOOP_VERSION}_${VERSION}'

- script: |
    export VERSION=$(cat arc/version) && \
    export SCALA_VERSION=2.12 && \
    docker push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_${SCALA_VERSION}_hadoop_${HADOOP_VERSION}_${VERSION}
  displayName: 'push triplai/arc:arc_${ARC_VERSION}_spark_${SPARK_VERSION}_scala_2.12_hadoop_${HADOOP_VERSION}_${VERSION}'  

- script: |
    export VERSION=$(cat arc-jupyter/version) && \
    export SCALA_VERSION=2.11 && \
    docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_${VERSION}
  displayName: 'push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.11_${VERSION}'  

- script: |
    export VERSION=$(cat arc-jupyter/version) && \
    export SCALA_VERSION=2.12 && \
    docker push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_${SCALA_VERSION}_${VERSION}
  displayName: 'push triplai/arc-jupyter:arc-jupyter_${ARC_JUPYTER_VERSION}_scala_2.12_${VERSION}'    